# RAG in 80 lines of code

It's simple. It's fast. It's easy. It's 80% of the way there for RAG.

For your application, RAG at 100% might still only solve 20% of your problem. 

It might be worth investing energy into the part that takes things to the next level.
But it's a good start. This is just one ingredient in building effective custom LLMs.

Specifically, RAG is [step 3](https://github.com/lamini-ai/lamini-sdk/tree/main/03_RAG) in the [Lamini SDK](https://github.com/lamini-ai/lamini-sdk/tree/main). Step through best practices for building custom LLMs on open-source there.

[Get your API key (free)](https://app.lamini.ai/). Easy steps to get started and install. [Let us know](https://www.lamini.ai/contact) if you want to chat about enterprise usage.


* PDFtoChat (https://github.com/Nutlope/pdftochat)
* RAGFlow (https://github.com/infiniflow/ragflow)